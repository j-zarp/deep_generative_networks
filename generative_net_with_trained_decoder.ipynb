{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "\n",
    "import os\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, BatchNormalization\n",
    "from keras.layers import Flatten, Dense, Dropout, ZeroPadding2D, Reshape, UpSampling2D\n",
    "from keras.layers.local import LocallyConnected1D\n",
    "from keras.layers.noise import GaussianDropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.utils.layer_utils import print_summary\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\" # uncomment this line to run the code on the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filter_id = 470 # candle class\n",
    "N = 3200 # feature vector size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def max_loss(y_true, y_pred):\n",
    "    return (1.-K.sum(tf.mul(y_true,y_pred),axis=-1))\n",
    "\n",
    "def max_metric(y_true, y_pred):\n",
    "    return (1.-max_loss(y_true,y_pred))\n",
    "\n",
    "def get_model():    \n",
    "    # generator\n",
    "    inputs = Input(shape=(N,), name='input')\n",
    "    \n",
    "    g0 = Reshape((N,1))(inputs)\n",
    "    g0 = GaussianDropout(0.05)(g0)\n",
    "    g1 = LocallyConnected1D(nb_filter=1, filter_length=1,\n",
    "                            init='one', activation='relu', bias=False,\n",
    "                            border_mode='valid',W_regularizer=l2(0.1))(g0)\n",
    "    g2 = Reshape((128,5,5))(g1)\n",
    "    \n",
    "    g3 = UpSampling2D(size=(2, 2))(g2) # 10x10\n",
    "    g3 = Convolution2D(512,2,2,activation='relu',border_mode='valid')(g3) # 9x9\n",
    "    g3 = BatchNormalization(mode = 0 , axis = 1)(g3)\n",
    "    g3 = Convolution2D(512,2,2,activation='relu',border_mode='same')(g3) # 9x9\n",
    "    g3 = BatchNormalization(mode = 0 , axis = 1)(g3)\n",
    "    \n",
    "    g4 = UpSampling2D(size=(2, 2))(g3) # 18x18\n",
    "    g4 = Convolution2D(256,3,3,activation='relu',border_mode='valid')(g4) # 16x16\n",
    "    g4 = BatchNormalization(mode = 0 , axis = 1)(g4)\n",
    "    g4 = Convolution2D(256,3,3,activation='relu',border_mode='same')(g4) # 16x16\n",
    "    g4 = BatchNormalization(mode = 0 , axis = 1)(g4)\n",
    "    \n",
    "    g5 = UpSampling2D(size=(2, 2))(g4) # 32x32\n",
    "    g5 = Convolution2D(256,3,3,activation='relu',border_mode='valid')(g5)# 30x30\n",
    "    g5 = BatchNormalization(mode = 0 , axis = 1)(g5)\n",
    "    g5 = Convolution2D(256,3,3,activation='relu',border_mode='same')(g5) # 30x30\n",
    "    g5 = BatchNormalization(mode = 0 , axis = 1)(g5)\n",
    "    \n",
    "    g6 = UpSampling2D(size=(2, 2))(g5) # 60x60\n",
    "    g6 = Convolution2D(128,3,3,activation='relu',border_mode='valid')(g6) # 58x58\n",
    "    g6 = BatchNormalization(mode = 0 , axis = 1)(g6)\n",
    "    g6 = Convolution2D(128,3,3,activation='relu',border_mode='same')(g6) # 58x58\n",
    "    g6 = BatchNormalization(mode = 0 , axis = 1)(g6)\n",
    "    \n",
    "    g7 = UpSampling2D(size=(2, 2))(g6) # 116x116\n",
    "    g7 = Convolution2D(128,4,4,activation='relu',border_mode='valid')(g7) # 113x113\n",
    "    g7 = BatchNormalization(mode = 0 , axis = 1)(g7)\n",
    "    g7 = Convolution2D(128,4,4,activation='relu',border_mode='same')(g7) # 113x113\n",
    "    g7 = BatchNormalization(mode = 0 , axis = 1)(g7)\n",
    "    \n",
    "    g8 = UpSampling2D(size=(2, 2))(g7) # 226x226\n",
    "    g8 = Convolution2D(64,3,3,activation='relu',border_mode='valid')(g8) # 224x224\n",
    "    g8 = BatchNormalization(mode = 0 , axis = 1)(g8)\n",
    "    g8 = Convolution2D(64,3,3,activation='relu',border_mode='same')(g8) # 224x224\n",
    "    g8 = BatchNormalization(mode = 0 , axis = 1)(g8)\n",
    "    g8 = Convolution2D(3,3,3,activation='linear',border_mode='same')(g8) # 224x224\n",
    "    g8 = BatchNormalization(mode = 0, axis = 1, name='image')(g8)\n",
    "    \n",
    "    temp = Model(input=inputs, output=g8)\n",
    "    offset = len(temp.layers)\n",
    "    \n",
    "    # discriminator  \n",
    "    vgg1 = ZeroPadding2D((1,1),input_shape=(3,224,224))(g8)\n",
    "    vgg2 = Convolution2D(64, 3, 3, activation='relu')(vgg1)\n",
    "    vgg3 = ZeroPadding2D((1,1))(vgg2)\n",
    "    vgg4 = Convolution2D(64, 3, 3, activation='relu')(vgg3)\n",
    "    vgg5 = MaxPooling2D((2,2), strides=(2,2))(vgg4)\n",
    "\n",
    "    vgg6 = ZeroPadding2D((1,1))(vgg5)\n",
    "    vgg7 = Convolution2D(128, 3, 3, activation='relu')(vgg6)\n",
    "    vgg8 = ZeroPadding2D((1,1))(vgg7)\n",
    "    vgg9 = Convolution2D(128, 3, 3, activation='relu')(vgg8)\n",
    "    vgg10 = MaxPooling2D((2,2), strides=(2,2))(vgg9)\n",
    "\n",
    "    vgg11 = ZeroPadding2D((1,1))(vgg10)\n",
    "    vgg12 = Convolution2D(256, 3, 3, activation='relu')(vgg11)\n",
    "    vgg13 = ZeroPadding2D((1,1))(vgg12)\n",
    "    vgg14 = Convolution2D(256, 3, 3, activation='relu')(vgg13)\n",
    "    vgg15 = ZeroPadding2D((1,1))(vgg14)\n",
    "    vgg16 = Convolution2D(256, 3, 3, activation='relu')(vgg15)\n",
    "    vgg17 = MaxPooling2D((2,2), strides=(2,2))(vgg16)\n",
    "\n",
    "    vgg18 = ZeroPadding2D((1,1))(vgg17)\n",
    "    vgg19 = Convolution2D(512, 3, 3, activation='relu')(vgg18)\n",
    "    vgg20 = ZeroPadding2D((1,1))(vgg19)\n",
    "    vgg21 = Convolution2D(512, 3, 3, activation='relu')(vgg20)\n",
    "    vgg22 = ZeroPadding2D((1,1))(vgg21)\n",
    "    vgg23 = Convolution2D(512, 3, 3, activation='relu')(vgg22)\n",
    "    vgg24 = MaxPooling2D((2,2), strides=(2,2))(vgg23)\n",
    "\n",
    "    vgg25 = ZeroPadding2D((1,1))(vgg24)\n",
    "    vgg26 = Convolution2D(512, 3, 3, activation='relu')(vgg25)\n",
    "    vgg27 = ZeroPadding2D((1,1))(vgg26)\n",
    "    vgg28 = Convolution2D(512, 3, 3, activation='relu')(vgg27)\n",
    "    vgg29 = ZeroPadding2D((1,1))(vgg28)\n",
    "    vgg30 = Convolution2D(512, 3, 3, activation='relu')(vgg29)\n",
    "    vgg31 = MaxPooling2D((2,2), strides=(2,2))(vgg30)\n",
    "\n",
    "    vgg32 = Flatten()(vgg31)\n",
    "    vgg33 = Dense(4096, activation='relu')(vgg32)\n",
    "    vgg34 = Dropout(0.5)(vgg33)\n",
    "    vgg35 = Dense(4096, activation='relu')(vgg34)\n",
    "    vgg36 = Dropout(0.5)(vgg35)\n",
    "    vgg37 = Dense(1000, activation='relu', name='vgg_class')(vgg36)\n",
    "    \n",
    "    # create model\n",
    "    model = Model(input=inputs, output=[vgg37,g8])\n",
    "    \n",
    "    # set generator weights\n",
    "    enc_size = 30\n",
    "    f = h5py.File('decoder_weights.h5')\n",
    "    for k, l in enumerate(f.attrs['layer_names']):\n",
    "        if(k<enc_size):\n",
    "            continue\n",
    "        g = f[l]\n",
    "        weight_names = [n.decode('utf8') for n in g.attrs['weight_names']]\n",
    "        weights = [g[weight_name] for weight_name in weight_names]\n",
    "        model.layers[k-enc_size+4].set_weights(weights)\n",
    "        model.layers[k-enc_size+4].trainable = False\n",
    "    f.close()\n",
    "    \n",
    "    # set discriminator weights (vgg)\n",
    "    f = h5py.File('vgg16_weights.h5')\n",
    "    for k in range(f.attrs['nb_layers']):\n",
    "        g = f['layer_{}'.format(k)]\n",
    "        weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "        model.layers[k+offset].set_weights(weights)\n",
    "        model.layers[k+offset].trainable = False\n",
    "    f.close()\n",
    "    \n",
    "    # set the locally connected layer weights to trainable\n",
    "    model.layers[3].trainable = True\n",
    "    \n",
    "    # compile model\n",
    "    sgd = SGD(lr=0.01, decay=0.0, momentum=0.1, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss=[max_loss, 'mse'], metrics=['mse'], loss_weights=[1.,0.])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create neural network\n",
    "model = get_model()\n",
    "print_summary(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reconstruct_image(im):\n",
    "    im2 = np.squeeze(im)*1\n",
    "    im2 = im2.transpose((1,2,0))\n",
    "    im2[:,:,0] += 103.939\n",
    "    im2[:,:,1] += 116.779\n",
    "    im2[:,:,2] += 123.68\n",
    "    im2 = im2.astype(np.uint8)\n",
    "    return cv2.cvtColor(im2,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def print_img(model,z=None):\n",
    "    if(z is None):\n",
    "        z = np.random.uniform(0,1,size=(1,N))\n",
    "    out = model.predict(z, batch_size=z.shape[0])\n",
    "    \n",
    "    activ = out[0][0]\n",
    "    img = out[1][0]\n",
    "\n",
    "    # change to RGB colors and rescale image\n",
    "    img -= np.min(img)\n",
    "    img /= np.max(img)\n",
    "    img *= 256.\n",
    "    img = cv2.cvtColor(img.astype('uint8').transpose(1,2,0), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(np.flipud(img))\n",
    "    plt.title('filter activation: '+str(activ[filter_id]))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    return img\n",
    "\n",
    "_ = print_img(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# training the model\n",
    "batch_size = 1\n",
    "n_samples = 40\n",
    "dummy_labels2 = np.zeros(shape=(n_samples,3,224,224))\n",
    "vgg_nclasses = 1000\n",
    "\n",
    "z = np.ones(shape=(n_samples,N))\n",
    "IMG = np.zeros((30,224,224,3))\n",
    "for k in np.arange(0,30):\n",
    "    dummy_labels1 = np.ones(shape=(n_samples,vgg_nclasses))*(-10./vgg_nclasses) # put a penalty to the other classes\n",
    "    dummy_labels1[:,filter_id] = 1.                                             # give a positive unit weight for the target class\n",
    "    out = model.fit(z, [dummy_labels1,dummy_labels2], batch_size=batch_size, nb_epoch=1, verbose=1)\n",
    "    \n",
    "    IMG[k,:,:,:] = print_img(model, z[0:1])\n",
    "\n",
    "# plotting the median of the last 10 iterations gives a smoother final image\n",
    "plt.figure()\n",
    "plt.imshow(np.flipud(np.median(IMG[20:,:,:,:],axis=0).astype('uint8')))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
